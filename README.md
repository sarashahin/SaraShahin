
### Hi there ðŸ‘‹, I am Sara Shahin

#### PhD Student in AI
#### MSc Artificial Intelligence
##### Bachelor of Science in Machine Learning and Artificial Intelligence

I am Sara and I am passionate about Data Science and Analytics. I have a Bachelor of Science in Machine Learning and Artificial Intelligence from Goldsmiths, University of London. Check out my [Portfolio](https://github.com/sarashahin/MyOfficialPortfolio/blob/main/README.md) for all of my projects, micro-projects, skills, certificates, and achievements.



Machine Learning Portfolio - Sara Shahin
This Portfolio is a compilation of all the Machine Learning and Deep Learning projects I have done for academic, self-learning and hobby purposes. This portfolio also contains my Achievements, skills, and certificates. It is updated on the regular basis.

Email: s.shahin@qmul.ac.uk

LinkedIn: https://www.linkedin.com/in/sara-shahin-3a842929/

Kaggle: https://www.kaggle.com/sarashahin

Achievements
PhD student at Queen Mary University of London, focusing on Unified Spatio-Temporal Biodiversity Modelling using AI.

I completed an MSc in Artificial Intelligence with Distinction at Anglia Ruskin University.

Recipient of a First-Class Honours Bachelor's Degree in Computer Science â€“ Machine Learning & Artificial Intelligence from Goldsmiths, University of London.

Awarded a Scholarship Genomic Data Science Course Bertelsmann Education Group

Awarded Women Students in Computer Science & Engineering Event in Milan Sponsor by First Ascent International.

Projects
Biometric Identification of Badger Individuals Using Camera Traps
I autonomously analyzed images for wildlife monitoring, focusing on developing a machine learning model for badger identification. By authoring a bespoke algorithm and collaborating with external partners, I successfully designed a software interface for biometric identification from camera trap imagery.

[https://github.com/sarashahin/Badger_AI]


Automate-Grading-Test-NART
This project focuses on the automated grading of premorbid ability tests, specifically reading tasks measured by the National Adult Reading Test (NART).

The goal is to classify the correct pronunciation of words to assess cognitive ability automatically.

[https://github.com/sarashahin/Automate-Grading-Test-NART]


My Image
[https://github.com/sarashahin/Breast_Cancer_Detection_Attention-UNet_Segmentatio/blob/main/Breast_Cancer_Detection_Attention_UNet_Segmentatio.ipynb]

Breast Cancer Detection Attention-UNet Segmentation
The aim of this research is to develop a model that can accurately segment breast ultrasound images, identifying areas that may indicate the presence of cancer. We are using deep learning techniques, specifically a custom UNet architecture with attention
mechanisms, to enhance the performance of image segmentation.


My Image

[https://github.com/sarashahin/ML_Research)

Enhancing and Evaluating the Robustness of Transfer-Learned Models with Ensemble Learning Against Noisy Data and Adversarial Attacks in Lung Tumour Imaging
This research inspects the robustness of transfer learned models such as DenseNet121 and ResNet50 against altered noise and adversarial attacks(FGSM) in the diagnosis of lung tumour. One of the leading causes of cancer related deaths is lung cancer and
requires advanced diagnostic tools for early detection. My study has evaluated these models under three conditions which are noisy, under adversarial attacks using the Fast Gradient Sign Method (FGSM) and with clean, unaltered test data. DenseNet121 has
demonstrated high quality performance in noisy environments with a 74% accuracy suggesting better management of data annotations. Conversely, ResNet50 was more resilient against adversarial attacks showing a 72% accuracy. Both models have indicated comparable efficacy on clean data with DenseNet121 at 78% accuracy. Notably, my innovative, ensemble approach combining these architectures shows improved performance on clean data at 78% accuracy and displays increased resistance to noise with 76% accuracy.


My Image
Multimodal-Fake-News-Detection

I examined different deep learning architectures for text classification such as Bidirectional long short-term memory (BiLSTM) and Bidirectional encoder representations from transformers (BERT). As a multimodal approach, I proposed a CNN architecture that combines both texts and images to classify the fake news.

My Image
RSNA Screening Mammography Breast Cancer Detection

The goal of this competition is to identify breast cancer using logistic regression model.


My Image
text-classification

Trained a Logistic Regression and Recurrent Neural Network (with LSTM layer) methods to carry out classification of Ironic and Sarcastic Tweets using Natural Language Processing. Pre-processing of the text data and word vectorisation was required before training these methods using TensorFlow. Evaluate the methods' performance based on Precision, Recall, and F-Scores.

My Image
Diabetes_Retinopathy_Dectetion_UNet_augment

The unet_model function defines the architecture of the U-Net model using a series of convolutional, pooling, and transpose convolutional layers. The model takes an input tensor of shape input_shape and returns an output tensor of shape (height, width, 1).


My Image
Google - Isolated Sign Language Recognition

The goal of this competition is to classify isolated American Sign Language (ASL) signs. Create a TensorFlow Lite model trained on labeled landmark data.


Micro Projects
Statistics and Machine Learning

Neural Network Word Embedding: Learn word embeddings jointly with the main task that care about (e.g. document classification or sentiment prediction). In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network. Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. These are called pre-trained word embeddings.

Analysis Data: Data Processing, Data Cleaning, Exploratory Analysis and Data Visualization

Pre-trained Inception V3 model Deepdream-keras: This code loads a pre-trained Inception V3 model, defines a function to read and preprocess an image, downsizes the image to make it easier to work with, and defines a function to calculate the loss for a given image and model. It also defines some utility functions to deprocess and display an image. It creates a feature extraction model using the specified layers of the loaded model. Uses gradient ascent to update the input image iteratively.

Challenges
Data Science Challenges: This repository contains codes of online Data Science challenges (From Hackerrank, etc.) solved by me.

Kaggle Competition RSNA Screening Mammography Breast Cancer Detection https://www.kaggle.com/sarashahin/competitions

Core Competencies
Methodologies : Machine Learning, Deep Learning, Natural Language Processing, Statistics and Data Analytics

Languages: Python (Pandas, Numpy, Scikit-Learn, Scipy, Keras, TensorFlow, Matplotlib), SQL, C++, JavaScript

Tools: MySQL, Tableau, Git, HTML, CSS, MS Excel

Certificates
Deep Learning by Stanford University Online
Machine Learning by Stanford University Online
IBM Data Science
IBM AI Engineering
Google IT Support

  











